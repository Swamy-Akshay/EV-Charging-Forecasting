{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Imports --------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, GRU, LSTM, Dense, Dropout, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d26a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Load Dataset --------------------\n",
    "file_path = \"ev_charging_patterns_augmented.csv\"\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"CSV file not found at {file_path}\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8620d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mugal\\AppData\\Local\\Temp\\ipykernel_8384\\2606197233.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Feature Engineering --------------------\n",
    "df['Charging Start Time'] = pd.to_datetime(df['Charging Start Time'], errors='coerce')\n",
    "df['Hour'] = df['Charging Start Time'].dt.hour\n",
    "df['Weekday'] = df['Charging Start Time'].dt.weekday\n",
    "df['IsWeekend'] = df['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "if 'Charging Power (kW)' in df.columns:\n",
    "    df['Power x Duration'] = df['Charging Power (kW)'] * df['Charging Duration (hours)']\n",
    "elif 'Charging Rate (kW)' in df.columns:\n",
    "    df['Power x Duration'] = df['Charging Rate (kW)'] * df['Charging Duration (hours)']\n",
    "else:\n",
    "    df['Power x Duration'] = 0\n",
    "\n",
    "if 'Vehicle Model' in df.columns:\n",
    "    df['Model x Weekday'] = df['Vehicle Model'].astype(str) + \"_\" + df['Weekday'].astype(str)\n",
    "else:\n",
    "    df['Model x Weekday'] = df['Weekday'].astype(str)\n",
    "\n",
    "# Lag and Rolling Features\n",
    "df['Lag1_Energy'] = df['Energy Consumed (kWh)'].shift(1)\n",
    "df['Lag2_Energy'] = df['Energy Consumed (kWh)'].shift(2)\n",
    "df['Lag1_Duration'] = df['Charging Duration (hours)'].shift(1)\n",
    "df['Rolling_Mean_Energy'] = df['Energy Consumed (kWh)'].rolling(window=3).mean()\n",
    "df['Rolling_Std_Energy'] = df['Energy Consumed (kWh)'].rolling(window=3).std()\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04df25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Data Split --------------------\n",
    "targets = ['Energy Consumed (kWh)', 'Charging Duration (hours)']\n",
    "drop_cols = ['User ID', 'Charging Start Time'] if 'User ID' in df.columns else ['Charging Start Time']\n",
    "X = df.drop(targets + drop_cols, axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50772fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Evaluate Helper --------------------\n",
    "def evaluate_model(name, preds):\n",
    "    results = {}\n",
    "    results['Model'] = name\n",
    "    for i, target in enumerate(['Energy Consumed (kWh)', 'Charging Duration (hours)']):\n",
    "        true = y_test.iloc[:, i]\n",
    "        pred = preds[i]\n",
    "        results[f\"{target.split()[0]} MAE\"] = mean_absolute_error(true, pred)\n",
    "        results[f\"{target.split()[0]} RMSE\"] = np.sqrt(mean_squared_error(true, pred))\n",
    "        results[f\"{target.split()[0]} R2\"] = r2_score(true, pred)\n",
    "        results[f\"{target.split()[0]} MAPE\"] = mean_absolute_percentage_error(true, pred)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c234b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 1: GRU + XGBoost --------------------\n",
    "def build_gru(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = GRU(64)(inp)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    out = Dense(2)(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(0.0005), loss='mse')\n",
    "    return model\n",
    "\n",
    "gru_model = build_gru((X_train_rnn.shape[1], X_train_rnn.shape[2]))\n",
    "gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "              callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "\n",
    "gru_train_pred = scaler_y.inverse_transform(gru_model.predict(X_train_rnn))\n",
    "gru_test_pred = scaler_y.inverse_transform(gru_model.predict(X_test_rnn))\n",
    "\n",
    "X_train_xgb = np.hstack([X_train_scaled, gru_train_pred])\n",
    "X_test_xgb = np.hstack([X_test_scaled, gru_test_pred])\n",
    "\n",
    "gru_xgboost_preds = []\n",
    "for i in range(2):\n",
    "    model = xgb.XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=5,\n",
    "                             subsample=0.9, colsample_bytree=0.8, random_state=42)\n",
    "    model.fit(X_train_xgb, y_train.iloc[:, i])\n",
    "    preds = model.predict(X_test_xgb)\n",
    "    gru_xgboost_preds.append(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d367dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 2: ANN + GRU --------------------\n",
    "ann_gru_model = Sequential([\n",
    "    GRU(64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2)\n",
    "])\n",
    "ann_gru_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "ann_gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                  callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "ann_gru_preds_scaled = ann_gru_model.predict(X_test_rnn)\n",
    "ann_gru_preds = scaler_y.inverse_transform(ann_gru_preds_scaled)\n",
    "ann_gru = [ann_gru_preds[:, 0], ann_gru_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd043638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 3: CNN + LSTM --------------------\n",
    "cnn_lstm_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    LSTM(64),\n",
    "    Dense(2)\n",
    "])\n",
    "cnn_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "cnn_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "cnn_lstm_preds = scaler_y.inverse_transform(cnn_lstm_model.predict(X_test_rnn))\n",
    "cnn_lstm = [cnn_lstm_preds[:, 0], cnn_lstm_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e0b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 4: GRU + LSTM --------------------\n",
    "gru_lstm_model = Sequential([\n",
    "    GRU(64, return_sequences=True, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    LSTM(64),\n",
    "    Dense(2)\n",
    "])\n",
    "gru_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "gru_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "gru_lstm_preds = scaler_y.inverse_transform(gru_lstm_model.predict(X_test_rnn))\n",
    "gru_lstm = [gru_lstm_preds[:, 0], gru_lstm_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34a9f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 5: ANN + LSTM --------------------\n",
    "ann_lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2)\n",
    "])\n",
    "ann_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "ann_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "ann_lstm_preds = scaler_y.inverse_transform(ann_lstm_model.predict(X_test_rnn))\n",
    "ann_lstm = [ann_lstm_preds[:, 0], ann_lstm_preds[:, 1]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d0a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 6: CNN + GRU --------------------\n",
    "cnn_gru_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    GRU(64),\n",
    "    Dense(2)\n",
    "])\n",
    "cnn_gru_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "cnn_gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                  callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "cnn_gru_preds = scaler_y.inverse_transform(cnn_gru_model.predict(X_test_rnn))\n",
    "cnn_gru = [cnn_gru_preds[:, 0], cnn_gru_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be052f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Run All Models --------------------\n",
    "results = []\n",
    "results.append(evaluate_model(\"ANN + GRU\", ann_gru))\n",
    "results.append(evaluate_model(\"CNN + LSTM\", cnn_lstm))\n",
    "results.append(evaluate_model(\"GRU + LSTM\", gru_lstm))\n",
    "results.append(evaluate_model(\"ANN + LSTM\", ann_lstm))\n",
    "results.append(evaluate_model(\"CNN + GRU\", cnn_gru))\n",
    "results.append(evaluate_model(\"GRU + XGBoost\", gru_xgboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e7b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Model Evaluation Results (Formatted Table):\n",
      "\n",
      "╒════╤═══════════════╤══════════════╤═══════════════╤═════════════╤═══════════════╤════════════════╤═════════════════╤═══════════════╤═════════════════╕\n",
      "│    │ Model         │   Energy MAE │   Energy RMSE │   Energy R2 │   Energy MAPE │   Charging MAE │   Charging RMSE │   Charging R2 │   Charging MAPE │\n",
      "╞════╪═══════════════╪══════════════╪═══════════════╪═════════════╪═══════════════╪════════════════╪═════════════════╪═══════════════╪═════════════════╡\n",
      "│  0 │ ANN + GRU     │       0.3857 │        0.5995 │      0.9993 │        0.0528 │         0.0285 │          0.0484 │        0.9978 │          0.0189 │\n",
      "├────┼───────────────┼──────────────┼───────────────┼─────────────┼───────────────┼────────────────┼─────────────────┼───────────────┼─────────────────┤\n",
      "│  1 │ CNN + LSTM    │       0.3621 │        0.463  │      0.9996 │        0.0488 │         0.0323 │          0.0569 │        0.997  │          0.0192 │\n",
      "├────┼───────────────┼──────────────┼───────────────┼─────────────┼───────────────┼────────────────┼─────────────────┼───────────────┼─────────────────┤\n",
      "│  2 │ GRU + LSTM    │       0.3995 │        0.5499 │      0.9994 │        0.0483 │         0.0285 │          0.0481 │        0.9978 │          0.0176 │\n",
      "├────┼───────────────┼──────────────┼───────────────┼─────────────┼───────────────┼────────────────┼─────────────────┼───────────────┼─────────────────┤\n",
      "│  3 │ ANN + LSTM    │       0.3933 │        0.5637 │      0.9994 │        0.0471 │         0.0351 │          0.0573 │        0.9969 │          0.0215 │\n",
      "├────┼───────────────┼──────────────┼───────────────┼─────────────┼───────────────┼────────────────┼─────────────────┼───────────────┼─────────────────┤\n",
      "│  4 │ CNN + GRU     │       0.3336 │        0.4502 │      0.9996 │        0.034  │         0.0341 │          0.0555 │        0.9971 │          0.0204 │\n",
      "├────┼───────────────┼──────────────┼───────────────┼─────────────┼───────────────┼────────────────┼─────────────────┼───────────────┼─────────────────┤\n",
      "│  5 │ GRU + XGBoost │       0.5828 │        0.9322 │      0.9982 │        0.0697 │         0.0259 │          0.0363 │        0.9988 │          0.0153 │\n",
      "╘════╧═══════════════╧══════════════╧═══════════════╧═════════════╧═══════════════╧════════════════╧═════════════════╧═══════════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Pretty Print Table --------------------\n",
    "from tabulate import tabulate\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n📊 Final Model Evaluation Results (Formatted Table):\\n\")\n",
    "print(tabulate(results_df.round(4), headers='keys', tablefmt='fancy_grid'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
