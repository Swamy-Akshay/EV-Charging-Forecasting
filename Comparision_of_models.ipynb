{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Imports --------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, GRU, LSTM, Dense, Dropout, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d26a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Load Dataset --------------------\n",
    "file_path = \"ev_charging_patterns_augmented.csv\"\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"CSV file not found at {file_path}\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8620d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mugal\\AppData\\Local\\Temp\\ipykernel_8384\\2606197233.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Feature Engineering --------------------\n",
    "df['Charging Start Time'] = pd.to_datetime(df['Charging Start Time'], errors='coerce')\n",
    "df['Hour'] = df['Charging Start Time'].dt.hour\n",
    "df['Weekday'] = df['Charging Start Time'].dt.weekday\n",
    "df['IsWeekend'] = df['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "if 'Charging Power (kW)' in df.columns:\n",
    "    df['Power x Duration'] = df['Charging Power (kW)'] * df['Charging Duration (hours)']\n",
    "elif 'Charging Rate (kW)' in df.columns:\n",
    "    df['Power x Duration'] = df['Charging Rate (kW)'] * df['Charging Duration (hours)']\n",
    "else:\n",
    "    df['Power x Duration'] = 0\n",
    "\n",
    "if 'Vehicle Model' in df.columns:\n",
    "    df['Model x Weekday'] = df['Vehicle Model'].astype(str) + \"_\" + df['Weekday'].astype(str)\n",
    "else:\n",
    "    df['Model x Weekday'] = df['Weekday'].astype(str)\n",
    "\n",
    "# Lag and Rolling Features\n",
    "df['Lag1_Energy'] = df['Energy Consumed (kWh)'].shift(1)\n",
    "df['Lag2_Energy'] = df['Energy Consumed (kWh)'].shift(2)\n",
    "df['Lag1_Duration'] = df['Charging Duration (hours)'].shift(1)\n",
    "df['Rolling_Mean_Energy'] = df['Energy Consumed (kWh)'].rolling(window=3).mean()\n",
    "df['Rolling_Std_Energy'] = df['Energy Consumed (kWh)'].rolling(window=3).std()\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04df25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Data Split --------------------\n",
    "targets = ['Energy Consumed (kWh)', 'Charging Duration (hours)']\n",
    "drop_cols = ['User ID', 'Charging Start Time'] if 'User ID' in df.columns else ['Charging Start Time']\n",
    "X = df.drop(targets + drop_cols, axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50772fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Evaluate Helper --------------------\n",
    "def evaluate_model(name, preds):\n",
    "    results = {}\n",
    "    results['Model'] = name\n",
    "    for i, target in enumerate(['Energy Consumed (kWh)', 'Charging Duration (hours)']):\n",
    "        true = y_test.iloc[:, i]\n",
    "        pred = preds[i]\n",
    "        results[f\"{target.split()[0]} MAE\"] = mean_absolute_error(true, pred)\n",
    "        results[f\"{target.split()[0]} RMSE\"] = np.sqrt(mean_squared_error(true, pred))\n",
    "        results[f\"{target.split()[0]} R2\"] = r2_score(true, pred)\n",
    "        results[f\"{target.split()[0]} MAPE\"] = mean_absolute_percentage_error(true, pred)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c234b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m224/224\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 1: GRU + XGBoost --------------------\n",
    "def build_gru(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = GRU(64)(inp)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    out = Dense(2)(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(0.0005), loss='mse')\n",
    "    return model\n",
    "\n",
    "gru_model = build_gru((X_train_rnn.shape[1], X_train_rnn.shape[2]))\n",
    "gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "              callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "\n",
    "gru_train_pred = scaler_y.inverse_transform(gru_model.predict(X_train_rnn))\n",
    "gru_test_pred = scaler_y.inverse_transform(gru_model.predict(X_test_rnn))\n",
    "\n",
    "X_train_xgb = np.hstack([X_train_scaled, gru_train_pred])\n",
    "X_test_xgb = np.hstack([X_test_scaled, gru_test_pred])\n",
    "\n",
    "gru_xgboost_preds = []\n",
    "for i in range(2):\n",
    "    model = xgb.XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=5,\n",
    "                             subsample=0.9, colsample_bytree=0.8, random_state=42)\n",
    "    model.fit(X_train_xgb, y_train.iloc[:, i])\n",
    "    preds = model.predict(X_test_xgb)\n",
    "    gru_xgboost_preds.append(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d367dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 2: ANN + GRU --------------------\n",
    "ann_gru_model = Sequential([\n",
    "    GRU(64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2)\n",
    "])\n",
    "ann_gru_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "ann_gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                  callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "ann_gru_preds_scaled = ann_gru_model.predict(X_test_rnn)\n",
    "ann_gru_preds = scaler_y.inverse_transform(ann_gru_preds_scaled)\n",
    "ann_gru = [ann_gru_preds[:, 0], ann_gru_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd043638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 3: CNN + LSTM --------------------\n",
    "cnn_lstm_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    LSTM(64),\n",
    "    Dense(2)\n",
    "])\n",
    "cnn_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "cnn_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "cnn_lstm_preds = scaler_y.inverse_transform(cnn_lstm_model.predict(X_test_rnn))\n",
    "cnn_lstm = [cnn_lstm_preds[:, 0], cnn_lstm_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e0b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 4: GRU + LSTM --------------------\n",
    "gru_lstm_model = Sequential([\n",
    "    GRU(64, return_sequences=True, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    LSTM(64),\n",
    "    Dense(2)\n",
    "])\n",
    "gru_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "gru_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "gru_lstm_preds = scaler_y.inverse_transform(gru_lstm_model.predict(X_test_rnn))\n",
    "gru_lstm = [gru_lstm_preds[:, 0], gru_lstm_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34a9f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 5: ANN + LSTM --------------------\n",
    "ann_lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2)\n",
    "])\n",
    "ann_lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "ann_lstm_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "ann_lstm_preds = scaler_y.inverse_transform(ann_lstm_model.predict(X_test_rnn))\n",
    "ann_lstm = [ann_lstm_preds[:, 0], ann_lstm_preds[:, 1]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d0a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\EV-Energy-Forecasting-Smart-Charging-Scheduler-main\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Model 6: CNN + GRU --------------------\n",
    "cnn_gru_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
    "    GRU(64),\n",
    "    Dense(2)\n",
    "])\n",
    "cnn_gru_model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "cnn_gru_model.fit(X_train_rnn, y_train_scaled, epochs=100, batch_size=32, validation_split=0.1,\n",
    "                  callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
    "cnn_gru_preds = scaler_y.inverse_transform(cnn_gru_model.predict(X_test_rnn))\n",
    "cnn_gru = [cnn_gru_preds[:, 0], cnn_gru_preds[:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be052f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Run All Models --------------------\n",
    "results = []\n",
    "results.append(evaluate_model(\"ANN + GRU\", ann_gru))\n",
    "results.append(evaluate_model(\"CNN + LSTM\", cnn_lstm))\n",
    "results.append(evaluate_model(\"GRU + LSTM\", gru_lstm))\n",
    "results.append(evaluate_model(\"ANN + LSTM\", ann_lstm))\n",
    "results.append(evaluate_model(\"CNN + GRU\", cnn_gru))\n",
    "results.append(evaluate_model(\"GRU + XGBoost\", gru_xgboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e7b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Final Model Evaluation Results (Formatted Table):\n",
      "\n",
      "â•’â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚    â”‚ Model         â”‚   Energy MAE â”‚   Energy RMSE â”‚   Energy R2 â”‚   Energy MAPE â”‚   Charging MAE â”‚   Charging RMSE â”‚   Charging R2 â”‚   Charging MAPE â”‚\n",
      "â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚  0 â”‚ ANN + GRU     â”‚       0.3857 â”‚        0.5995 â”‚      0.9993 â”‚        0.0528 â”‚         0.0285 â”‚          0.0484 â”‚        0.9978 â”‚          0.0189 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  1 â”‚ CNN + LSTM    â”‚       0.3621 â”‚        0.463  â”‚      0.9996 â”‚        0.0488 â”‚         0.0323 â”‚          0.0569 â”‚        0.997  â”‚          0.0192 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  2 â”‚ GRU + LSTM    â”‚       0.3995 â”‚        0.5499 â”‚      0.9994 â”‚        0.0483 â”‚         0.0285 â”‚          0.0481 â”‚        0.9978 â”‚          0.0176 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  3 â”‚ ANN + LSTM    â”‚       0.3933 â”‚        0.5637 â”‚      0.9994 â”‚        0.0471 â”‚         0.0351 â”‚          0.0573 â”‚        0.9969 â”‚          0.0215 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  4 â”‚ CNN + GRU     â”‚       0.3336 â”‚        0.4502 â”‚      0.9996 â”‚        0.034  â”‚         0.0341 â”‚          0.0555 â”‚        0.9971 â”‚          0.0204 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  5 â”‚ GRU + XGBoost â”‚       0.5828 â”‚        0.9322 â”‚      0.9982 â”‚        0.0697 â”‚         0.0259 â”‚          0.0363 â”‚        0.9988 â”‚          0.0153 â”‚\n",
      "â•˜â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Pretty Print Table --------------------\n",
    "from tabulate import tabulate\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š Final Model Evaluation Results (Formatted Table):\\n\")\n",
    "print(tabulate(results_df.round(4), headers='keys', tablefmt='fancy_grid'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
